{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tristantoupin/ECSE415-FinalProject/blob/master/SVM_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0RBxs9-NPHd"
   },
   "source": [
    "# Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8geB0RRQNPHg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOqQbfR4NV3W"
   },
   "source": [
    "### Determine whether to use the dataset from Google Cloud storage or local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dbjv-u2wNZc5",
    "outputId": "cc82c4ff-3480-42ec-f3e5-2c3ff5baf260"
   },
   "outputs": [],
   "source": [
    "# Change this value depending whether you're using a cloud or local environment\n",
    "is_using_cloud = False\n",
    "\n",
    "if is_using_cloud:\n",
    "    import tarfile\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    path_classification = '/content/gdrive/My Drive/Colab Notebooks/Project/MIO-TCD-Classification.tar'\n",
    "    tar = tarfile.open(path_classification)\n",
    "else:\n",
    "    path_classification = './MIO-TCD-Classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fVpEwwNPHm"
   },
   "source": [
    "### Helper functions for image plotting, importing, and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nrnfSRdNPHo"
   },
   "outputs": [],
   "source": [
    "def plot_images(list_of_images, max_col = 4):\n",
    "    \"\"\"\n",
    "    @brief Plot a list of given images with\n",
    "    @param list_of_images List of images to plot\n",
    "    @param max_col Number of colomns to plot your figures\n",
    "    \"\"\"\n",
    "    n = len(list_of_images)\n",
    "    if n == 1:\n",
    "        plt.imshow(list_of_images[0]); plt.axis('off'); plt.show()\n",
    "    else:\n",
    "        # get number of columns and rows required\n",
    "        r, c = 1, n\n",
    "        if n > max_col:\n",
    "            c = max_col\n",
    "            r = int(math.ceil(n/max_col))\n",
    "    \n",
    "        fig = plt.figure(figsize=(17, max_col * r))\n",
    "        for i, (img) in enumerate(list_of_images):\n",
    "            ax = fig.add_subplot(r, c, (i+1))\n",
    "            ax.set_title(\"Image \" + str(i))\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBC075JTNPHx"
   },
   "outputs": [],
   "source": [
    "def pad_resize_images(img_list, output_size):\n",
    "    \"\"\"\n",
    "    @brief Resize each image within a list to a given shape while also keeping its aspect ratio by the use of padding\n",
    "    @param img_list The list of images to resize\n",
    "    @param output_size The shape of the output images are output_size x output_size\n",
    "    \"\"\"\n",
    "    BLACK = 0\n",
    "    result = np.empty_like(img_list)\n",
    "    \n",
    "    for i, img in enumerate(img_list):\n",
    "        \n",
    "        height, width = img.shape\n",
    "        ratio = float(output_size) / max([height, width])\n",
    "        height_new, width_new = tuple([int(val * ratio) for val in (height, width)])\n",
    "        img_resized = cv2.resize(img, (height_new, width_new))\n",
    "        \n",
    "        height_adjust = output_size - height_new\n",
    "        width_adjust = output_size - width_new\n",
    "        \n",
    "        top = math.ceil(height_adjust / 2)\n",
    "        bot = height_adjust - top\n",
    "        left = math.ceil(width_adjust / 2)\n",
    "        right = width_adjust - left\n",
    "        \n",
    "        result[i] = cv2.resize(\n",
    "            cv2.copyMakeBorder(img_resized, top, bot, left, right, cv2.BORDER_CONSTANT, value=BLACK),\n",
    "            (output_size, output_size))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_random_clf(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    clf = DummyClassifier(strategy = 'uniform', random_state = r)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    preds = clf.predict(x_test)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric\n",
    "    \n",
    "def performance_majority_classifier(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    most_common_val = stats.mode(y_tr).mode[0]\n",
    "    preds = np.full((y_test.shape), most_common_val)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric\n",
    "\n",
    "def fine_tune_svm(x_tr, y_tr, folds=10):\n",
    "  # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "    models = []\n",
    "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=folds,\n",
    "                       scoring = 'accuracy', n_jobs = -1, verbose = 1)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    models.append(clf)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    return models\n",
    "\n",
    "def compute_svm_predictions(x_train, y_train, x_val):\n",
    "    model = svm.SVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_val)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zshDMw92NPH3"
   },
   "source": [
    "#### Import a subset of or all images for each category with their relevant label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eM9c9bPhNPH4",
    "outputId": "91cf0150-6b66-445c-ceba-15ed47ab7053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.4338068962097168\n"
     ]
    }
   ],
   "source": [
    "path_classification_train = os.path.join(path_classification, 'train')\n",
    "\n",
    "#\n",
    "# Change this number if you want more or less images. Set it to -1 if you want all images\n",
    "#\n",
    "number_images_category = 10\n",
    "categories = os.listdir(path_classification_train)\n",
    "classification_images = []\n",
    "y_tr = []\n",
    "\n",
    "start_time = time.time()\n",
    "for category in categories:\n",
    "    path_category = os.path.join(path_classification_train, category)\n",
    "    for i, image_name in enumerate(os.listdir(path_category)):\n",
    "        \n",
    "        if i == number_images_category:\n",
    "            break\n",
    "            \n",
    "        image = cv2.imread(os.path.join(path_category, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        classification_images.append(image)\n",
    "        \n",
    "        label = categories.index(category)\n",
    "        y_tr.append(label)\n",
    "\n",
    "classification_images = np.array(classification_images)\n",
    "y_tr = np.array(y_tr)\n",
    "\n",
    "assert len(classification_images) == len(categories) * number_images_category\n",
    "assert len(classification_images) == len(y_tr)\n",
    "\n",
    "print('Elapsed Time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqYkqHZFNPH-"
   },
   "source": [
    "#### Import a number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ_wKpRgNPH_"
   },
   "outputs": [],
   "source": [
    "path_classification_test = os.path.join(path_classification, 'test')\n",
    "\n",
    "# For now I'll take the same amount test of images as I have for training\n",
    "number_images_test = len(classification_images)\n",
    "images_test = []\n",
    "\n",
    "for i, image_name in enumerate(os.listdir(path_classification_test)):\n",
    "    if i == number_images_test:\n",
    "        break\n",
    "    \n",
    "    image = cv2.imread(os.path.join(path_classification_test, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "    images_test.append(image)\n",
    "    \n",
    "images_test = np.array(images_test)\n",
    "assert len(images_test) == number_images_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57hVorGKNPIC"
   },
   "source": [
    "#### Pad images to maintain one common aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRfs84gNNPID"
   },
   "outputs": [],
   "source": [
    "# largest_width = np.max([x.shape[0] for x in classification_images])\n",
    "# largest_height = np.max([x.shape[1] for x in classification_images])\n",
    "\n",
    "size = 128\n",
    "padded_images_train = pad_resize_images(classification_images, size)\n",
    "padded_images_test = pad_resize_images(images_test, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkF1a-_HNPIH"
   },
   "source": [
    "#### Flatten images to prepare for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyEoUUyeNPII"
   },
   "outputs": [],
   "source": [
    "x_tr = np.array([x.flatten() for x in padded_images_train])\n",
    "y_test = np.array([x.flatten() for x in padded_images_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GX87L3oBNPIO",
    "outputId": "c55a8dd7-8d3f-4138-d7c9-af4f1dff862c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_svm_predictions(x_tr, y_tr, y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and fine tune SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "[GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params=None, iid='warn', n_jobs=-1,\n",
      "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=1)]\n"
     ]
    }
   ],
   "source": [
    "best_svm_model = fine_tune_svm(x_tr, y_tr, folds=10)\n",
    "print(best_svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = svm.SVC(C = 1, gamma = 0.001, kernel = 'linear')\n",
    "best_model.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_model.predict(x_val)\n",
    "print(preds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "SVM_classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
