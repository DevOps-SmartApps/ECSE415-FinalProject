{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tristantoupin/ECSE415-FinalProject/blob/master/SVM_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0RBxs9-NPHd"
   },
   "source": [
    "# Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8geB0RRQNPHg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOqQbfR4NV3W"
   },
   "source": [
    "### Determine whether to use the dataset from Google Cloud storage or local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dbjv-u2wNZc5",
    "outputId": "cc82c4ff-3480-42ec-f3e5-2c3ff5baf260"
   },
   "outputs": [],
   "source": [
    "# Change this value depending whether you're using a cloud or local environment\n",
    "is_using_cloud = False\n",
    "\n",
    "if is_using_cloud:\n",
    "    import tarfile\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    \n",
    "    path_classification = '/content/gdrive/My Drive/Colab Notebooks/Project/MIO-TCD-Classification.tar'\n",
    "    tar = tarfile.open(path_classification)\n",
    "else:\n",
    "    path_classification = './MIO-TCD-Classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fVpEwwNPHm"
   },
   "source": [
    "### Helper functions for image plotting, importing, and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nrnfSRdNPHo"
   },
   "outputs": [],
   "source": [
    "def plot_images(list_of_images, max_col = 4):\n",
    "    \"\"\"\n",
    "    @brief Plot a list of given images with\n",
    "    @param list_of_images List of images to plot\n",
    "    @param max_col Number of colomns to plot your figures\n",
    "    \"\"\"\n",
    "    n = len(list_of_images)\n",
    "    if n == 1:\n",
    "        plt.imshow(list_of_images[0]); plt.axis('off'); plt.show()\n",
    "    else:\n",
    "        # get number of columns and rows required\n",
    "        r, c = 1, n\n",
    "        if n > max_col:\n",
    "            c = max_col\n",
    "            r = int(math.ceil(n/max_col))\n",
    "    \n",
    "        fig = plt.figure(figsize=(17, max_col * r))\n",
    "        for i, (img) in enumerate(list_of_images):\n",
    "            ax = fig.add_subplot(r, c, (i+1))\n",
    "            ax.set_title(\"Image \" + str(i))\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBC075JTNPHx"
   },
   "outputs": [],
   "source": [
    "def pad_resize_images(img_list, output_size):\n",
    "    \"\"\"\n",
    "    @brief Resize each image within a list to a given shape while also keeping its aspect ratio by the use of padding\n",
    "    @param img_list The list of images to resize\n",
    "    @param output_size The shape of the output images are output_size x output_size\n",
    "    \"\"\"\n",
    "    BLACK = 0\n",
    "    result = np.empty_like(img_list)\n",
    "    \n",
    "    for i, img in enumerate(img_list):\n",
    "        \n",
    "        height, width = img.shape\n",
    "        ratio = float(output_size) / max([height, width])\n",
    "        height_new, width_new = tuple([int(val * ratio) for val in (height, width)])\n",
    "        img_resized = cv2.resize(img, (height_new, width_new))\n",
    "        \n",
    "        height_adjust = output_size - height_new\n",
    "        width_adjust = output_size - width_new\n",
    "        \n",
    "        top = math.ceil(height_adjust / 2)\n",
    "        bot = height_adjust - top\n",
    "        left = math.ceil(width_adjust / 2)\n",
    "        right = width_adjust - left\n",
    "        \n",
    "        result[i] = cv2.resize(\n",
    "            cv2.copyMakeBorder(img_resized, top, bot, left, right, cv2.BORDER_CONSTANT, value=BLACK),\n",
    "            (output_size, output_size))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_random_clf(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    clf = DummyClassifier(strategy = 'uniform', random_state = r)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    preds = clf.predict(x_test)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric\n",
    "    \n",
    "def performance_majority_classifier(x_tr, y_tr, x_test, y_test, r = 1234):\n",
    "    most_common_val = stats.mode(y_tr).mode[0]\n",
    "    preds = np.full((y_test.shape), most_common_val)\n",
    "    metric = metrics.classification_report(y_test, preds)\n",
    "    return metric\n",
    "\n",
    "def fine_tune_svm(x_tr, y_tr, folds=10):\n",
    "  # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "    models = []\n",
    "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=folds,\n",
    "                       scoring = 'accuracy', n_jobs = -1, verbose = 1)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    models.append(clf)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    return models\n",
    "\n",
    "def compute_svm_predictions(x_train, y_train, x_val):\n",
    "    model = svm.SVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_val)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zshDMw92NPH3"
   },
   "source": [
    "#### Import a subset of or all images for each category with their relevant label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eM9c9bPhNPH4",
    "outputId": "91cf0150-6b66-445c-ceba-15ed47ab7053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 18.414430618286133\n",
      "Number of Images: 46017\n"
     ]
    }
   ],
   "source": [
    "path_classification_train = os.path.join(path_classification, 'train')\n",
    "\n",
    "#\n",
    "# Change this number if you want more or less images. Set it to -1 if you want all images\n",
    "# NOTE: This will ATTEMPT to have the same number of images per category. The categories\n",
    "# have a large difference in number of images.\n",
    "#\n",
    "number_images_category = 5000\n",
    "categories = os.listdir(path_classification_train)\n",
    "classification_images = []\n",
    "y_tr = []\n",
    "\n",
    "start_time = time.time()\n",
    "for category in categories:\n",
    "    path_category = os.path.join(path_classification_train, category)\n",
    "    for i, image_name in enumerate(os.listdir(path_category)):\n",
    "        \n",
    "        if i == number_images_category:\n",
    "            break\n",
    "            \n",
    "        image = cv2.imread(os.path.join(path_category, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "        classification_images.append(image)\n",
    "        \n",
    "        label = categories.index(category)\n",
    "        y_tr.append(label)\n",
    "\n",
    "classification_images = np.array(classification_images)\n",
    "y_tr = np.array(y_tr)\n",
    "\n",
    "assert len(classification_images) == len(y_tr)\n",
    "\n",
    "print('Elapsed Time:', time.time() - start_time)\n",
    "print('Number of Images:', len(classification_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_images, y_tr = shuffle(classification_images, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqYkqHZFNPH-"
   },
   "source": [
    "#### Import a number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ_wKpRgNPH_"
   },
   "outputs": [],
   "source": [
    "path_classification_test = os.path.join(path_classification, 'test')\n",
    "\n",
    "#\n",
    "# Change this number if you want more or less images. Set it to -1 if you want all images\n",
    "#\n",
    "number_images_test = 0\n",
    "images_test = []\n",
    "\n",
    "for i, image_name in enumerate(os.listdir(path_classification_test)):\n",
    "    if i == number_images_test:\n",
    "        break\n",
    "    \n",
    "    image = cv2.imread(os.path.join(path_classification_test, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "    images_test.append(image)\n",
    "    \n",
    "images_test = np.array(images_test)\n",
    "assert len(images_test) == number_images_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract HoG features from training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\skimage\\feature\\_hog.py:150: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15. To supress this message specify explicitly the normalization method.\n",
      "  skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "hog_images = []\n",
    "\n",
    "\n",
    "for image in classification_images[:1000]:\n",
    "\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=False)\n",
    "    \n",
    "    hog_images.append(hog_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57hVorGKNPIC"
   },
   "source": [
    "#### Pad images to maintain one common aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRfs84gNNPID"
   },
   "outputs": [],
   "source": [
    "size = 128\n",
    "padded_images_train = pad_resize_images(classification_images, size)\n",
    "padded_images_hog = pad_resize_images(hog_images, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkF1a-_HNPIH"
   },
   "source": [
    "#### Flatten images to prepare for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyEoUUyeNPII"
   },
   "outputs": [],
   "source": [
    "x_train = np.array([x.flatten() for x in padded_images_train])\n",
    "x_train_hog = np.array([x.flatten() for x in padded_images_hog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:   14.8s finished\n",
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:   14.7s finished\n",
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "svm_model = fine_tune_svm(x_train[:100], y_tr[:100], folds=10)\n",
    "svm_model_hog = fine_tune_svm(x_train_hog[:100], y_tr[:100], folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = svm_model[0]\n",
    "best_svm_model_hog = svm_model_hog[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non HoG Model Correct Predictions: 38\n",
      "HoG Model Correct Predictions: 3\n"
     ]
    }
   ],
   "source": [
    "model_predictions = best_svm_model.predict(x_train[300:400])\n",
    "model_hog_predictions = best_svm_model_hog.predict(x_train[300:400]) \n",
    "\n",
    "results = []\n",
    "results_hog = []\n",
    "\n",
    "for i, category in enumerate(y_tr[300:400]):\n",
    "    results.append(model_predictions[i] == category)\n",
    "    results_hog.append(model_hog_predictions[i] == category)\n",
    "\n",
    "print('Non HoG Model Correct Predictions:', np.count_nonzero(results))\n",
    "print('HoG Model Correct Predictions:', np.count_nonzero(results_hog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and fine tune SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:   14.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\envs\\opencv-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "[GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params=None, iid='warn', n_jobs=-1,\n",
      "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=1)]\n",
      "Elapsed Time 14.698078155517578\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "best_svm_model = fine_tune_svm(x_tr[:100], y_tr[:100], folds=10)\n",
    "print(best_svm_model)\n",
    "print('Elapsed Time', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = svm.SVC(C = 1, gamma = 0.001, kernel = 'linear')\n",
    "best_model.fit(x_tr[:100], y_tr[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  7  1 10  4 10  4 10 10  4  5  9  7  4  1  1  1  1  9  0  1  1  9  4\n",
      "  3  4  5  1  7  5  2  9  5  1  1  9  1  7  7  5  1  2  2  1  1  4  4  1\n",
      "  7  1  1  8  2  1  5  7  2  9  1  2  4  1  2  1  1  1  8  2  1  1  3  1\n",
      "  1  7  5 10  7  1  4  1  5 10  7  4  2  1  4  7  1  4  4  2  4  1  0  1\n",
      "  4  2  2  5]\n"
     ]
    }
   ],
   "source": [
    "preds = best_model.predict(x_tr[100:200])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "SVM_classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
